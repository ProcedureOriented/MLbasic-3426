{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据集加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n此处使用transform而不是fit_transform的原因：\\n如果使用fit_transform则是先对测试集的特征的数据做拟合，得到其各个特征的最大值和最小值，然后进行归一处理\\n这样就会导致得到的X_train和X_test的计算模型不同，所以不使用fit_transform，直接transform\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# 载入Iris数据集\n",
    "iris = datasets.load_iris()\n",
    "# print(iris)\n",
    "X = iris.data # 获取iris数据集data属性的值，二维，行数等于样本数，列数等于特征数\n",
    "# print(X)\n",
    "Y = iris.target # 获取iris数据集target属性的值\n",
    "# print(Y)\n",
    "# 随机划分训练集与测试集\n",
    "X_pretrain, X_pretest, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "# 归一化\n",
    "minMax = MinMaxScaler() # 创建一个minMax对象\n",
    "X_train = minMax.fit_transform(X_pretrain)\n",
    "'''\n",
    "使用minMax对象中的fit_transform方法对训练集做归一化处理\n",
    "此处使用fit_transform是对训练集的特征的数据做拟合，得到其各个特征的最大值和最小值，然后transform进行归一化处理\n",
    "'''\n",
    "X_test = minMax.transform(X_pretest) # 使用minMax对象中的fit_transform方法对测试集做归一化处理\n",
    "'''\n",
    "此处使用transform而不是fit_transform的原因：\n",
    "如果使用fit_transform则是先对测试集的特征的数据做拟合，得到其各个特征的最大值和最小值，然后进行归一处理\n",
    "这样就会导致得到的X_train和X_test的计算模型不同，所以不使用fit_transform，直接transform\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.导入包与定义结点类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "class decisionnode: # 定义结点类\n",
    "    def __init__(self, d=None, thre=None, results=None, min_sample_number=None, lb=None, rb=None, max_label=None):\n",
    "        self.d = d # d 表示用于划分的属性索引\n",
    "        self.thre = thre # thre 表示划分所使用的阈值，每次分裂将样本集分为 2 个子集\n",
    "        self.results = results # 叶结点所代表的类别\n",
    "        self.min_sample_number = min_sample_number # 存储分支结点的最小样本量\n",
    "        self.lb = lb # 左子结点，对应属性值不大于 thre 的那些样本所在的结点\n",
    "        self.rb = rb # 右子结点，对应属性值大于 thre 的那些样本所在的结点\n",
    "        self.max_label = max_label # 记录当前结点包含的样本中样本比例最高的类别\n",
    "\n",
    "min_sample_number = 10 #设置分支结点中包含的最小样本数（即如果一个结点中包含的样本数小于该值则停止分裂）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.计算信息熵\n",
    "- 首先获取labels列表\n",
    "- 其次计算信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    # 计算信息熵，y为labels，是包含了训练集中每个样本的label值的一个列表\n",
    "    # 先获取category，即label的去重\n",
    "    if y.size > 1:  # size()用来获取元素个数。如果y中元素个数大于1则需要使用set()函数先将\n",
    "        category = list(set(y)) # 获取labels列表：y是训练集中每个样本的label值，set()将用来去重，得到去重后的标签个数，而后将其转成列表\n",
    "    else: #\n",
    "        category = [y.item()]  #\n",
    "        y = [y.item()] # 利用item()对y进行遍历，并将y中的所有元素整合为列表y\n",
    "    ent = 0\n",
    "    # 而后在\n",
    "    for label in category: # 计算信息熵\n",
    "        p = len([label_ for label_ in y if label_ == label]) / len(y) # p：样本集合中第k类样本所占的比例\n",
    "        ent += -p * math.log(p, 2) # 计算信息熵，累加\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.计算基尼值\n",
    "- 首先获取labels列表\n",
    "- 其次计算基尼指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y):\n",
    "    # 计算基尼值，y 为 labels\n",
    "    category = list(set(y)) # 获取labels列表\n",
    "    gini = 1\n",
    "    for label in category:\n",
    "        p = len([label_ for label_ in y if label_ == label]) / len(y)\n",
    "        gini += -p * p # 基尼值：1-（两个样本为同一类的概率的累加）\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.基于最大信息增益计算最优划分阈值\n",
    "- 利用for循环，基于信息增益，对候选划分点不断迭代，最终得到最大的信息增益和最优阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GainEnt_max(X, y, d):\n",
    "    # 基于最大信息增益计算最优划分阈值，X 为样本集的属性值，y 为目标值，d 是当前划分使用的属性索引\n",
    "    ent_X = entropy(y) # 信息熵\n",
    "    X_attr = X[:, d] # 获取样本集中索引d对应的属性的值\n",
    "    X_attr = list(set(X_attr)) \n",
    "    X_attr = sorted(X_attr) # d是我们使用的分类属性，是连续性数值数据，所以需要对连续型数值进行处理，这里利用sorted()函数对X_attr进行升序排列，以便后续选取中位点对连续值处理\n",
    "    Gain = 0\n",
    "    thre = 0\n",
    "    for i in range(len(X_attr) - 1):\n",
    "        thre_temp = (X_attr[i] + X_attr[i + 1]) / 2 # 候选划分点\n",
    "        y_small_index = [i_arg for i_arg in range(len(X[:, d])) if X[i_arg, d] <= thre_temp] # 获取属性值小于等于候选划分点的索引列表\n",
    "        y_big_index = [i_arg for i_arg in range(len(X[:, d])) if X[i_arg, d] > thre_temp] # 获取属性值大于候选划分点的索引列表\n",
    "        y_small = y[y_small_index] \n",
    "        y_big = y[y_big_index] \n",
    "        Gain_temp = ent_X - (len(y_small) / len(y)) * entropy(y_small) - (len(y_big) / len(y)) * entropy(y_big) # 计算信息增益\n",
    "        if Gain < Gain_temp: # 选取信息增益较大的\n",
    "            Gain = Gain_temp # 信息增益\n",
    "            thre = thre_temp # 最优阈值\n",
    "    return Gain, thre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.基于最小基尼指数计算最优划分阈值\n",
    "- 利用for循环，基于基尼指数，对候选划分点不断迭代，最终得到最小的基尼指数和最优阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini_index_min(X, y, d):\n",
    "    # 基于最小基尼指数计算最优划分阈值，X 为样本集的属性值，y 为目标值，d 是当前划分使用的属性索引\n",
    "    X_attr = X[:, d] # 获取样本集中索引d对应的属性的值\n",
    "    X_attr = list(set(X_attr))\n",
    "    X_attr = sorted(X_attr) # 升序排列\n",
    "    Gini_index = 1\n",
    "    thre = 0\n",
    "    for i in range(len(X_attr) - 1):\n",
    "        thre_temp = (X_attr[i] + X_attr[i + 1]) / 2 # 候选划分点\n",
    "        y_small_index = [i_arg for i_arg in range(len(X[:, d])) if X[i_arg, d] <= thre_temp] # 获取属性值小于等于候选划分点的索引列表\n",
    "        y_big_index = [i_arg for i_arg in range(len(X[:, d])) if X[i_arg, d] > thre_temp] # 获取属性值大于候选划分点的索引列表\n",
    "        y_small = y[y_small_index]\n",
    "        y_big = y[y_big_index]\n",
    "        Gini_index_temp = (len(y_small) / len(y)) * Gini(y_small) + (len(y_big) / len(y)) * Gini(y_big) # 计算基尼指数\n",
    "        if Gini_index > Gini_index_temp: # 选取基尼指数较小的\n",
    "            Gini_index = Gini_index_temp # 基尼指数\n",
    "            thre = thre_temp # 最优阈值\n",
    "    return Gini_index, thre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.基于信息增益选择最优属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_based_on_GainEnt(X, y):\n",
    "    # 基于信息增益选择最优属性，X 为样本集的属性值，y 为目标值\n",
    "    D = np.arange(len(X[0]))\n",
    "    Gain_max = 0\n",
    "    thre_ = 0\n",
    "    d_ = 0\n",
    "    for d in D:\n",
    "        Gain, thre = GainEnt_max(X, y, d) # 计算该属性的最优划分阈值\n",
    "        if Gain_max < Gain:\n",
    "            Gain_max = Gain # 选取信息增益较大的\n",
    "            thre_ = thre # 划分阈值\n",
    "            d_ = d # 属性索引\n",
    "    return Gain_max, thre_, d_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.基于基尼指数选择最优属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_based_on_Giniindex(X, y):\n",
    "    # 基于基尼指数选择最优属性，X 为样本集的属性值，y 为目标值\n",
    "    D = np.arange(len(X[0]))\n",
    "    Gini_Index_Min = 1\n",
    "    thre_ = 0\n",
    "    d_ = 0\n",
    "    for d in D:\n",
    "        Gini_index, thre = Gini_index_min(X, y, d) #计算该属性的最优划分阈值\n",
    "        if Gini_Index_Min > Gini_index:\n",
    "            Gini_Index_Min = Gini_index # 选取基尼指数较小的\n",
    "            thre_ = thre # 划分阈值\n",
    "            d_ = d # 属性索引\n",
    "    return Gini_Index_Min, thre_, d_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.按照索引为 d 的属性、以 thre 为阈值将数据分为两个子集并返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devide_group(X, y, thre, d):\n",
    "    # 按照索引为 d 的属性、以 thre 为阈值将数据分为两个子集并返回\n",
    "    X_in_d = X[:, d]\n",
    "    x_small_index = [i_arg for i_arg in range(len(X[:, d])) if X[i_arg, d] <= thre] # 获取属性值小于等于候选划分点的索引列表\n",
    "    x_big_index = [i_arg for i_arg in range(len(X[:, d])) if X[i_arg, d] > thre] # 获取属性值大于候选划分点的索引列表\n",
    "\n",
    "    X_small = X[x_small_index] \n",
    "    y_small = y[x_small_index] \n",
    "    X_big = X[x_big_index] \n",
    "    y_big = y[x_big_index] \n",
    "    return X_small, y_small, X_big, y_big "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.计算样本集中样本占比最多的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxlabel(y): \n",
    "    # 计算样本集中样本占比最多的类别\n",
    "    label_ = Counter(y).most_common(1) # 利用collections.Counter中的most_common()方法得到样本中出现最多的1个类与次数\n",
    "    return label_[0][0] # 得到样本中出现次数最多的1个类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildtree(X, y, method='Gini'):\n",
    "    # 递归的方式构建决策树\n",
    "    if y.size > 1:\n",
    "        if method == 'Gini':\n",
    "            Gain_max, thre, d = attribute_based_on_Giniindex(X, y) # 上面定义的基于基尼指数选择最优属性的函数\n",
    "        elif method == 'GainEnt':\n",
    "            Gain_max, thre, d = attribute_based_on_GainEnt(X, y) # 上面定义的基于信息增益选择最优属性的函数\n",
    "        if len(list(y)) >= min_sample_number and ((Gain_max > 0 and method == 'GainEnt') or (Gain_max >=0 and method == 'Gini')):\n",
    "            X_small, y_small, X_big, y_big = devide_group(X, y, thre, d) # 上面定义的划分子集的函数\n",
    "            left_branch = buildtree(X_small, y_small, method=method) # 左子结点，对应属性值不大于thre的那些样本所在的结点\n",
    "            right_branch = buildtree(X_big, y_big, method=method) # 右子结点，对应属性值大于thre的那些样本所在的结点\n",
    "            max_label = maxlabel(y) # 上面定义的计算样本集中样本占比最多的类别的函数，max_label用来记录当前结点包含的样本中样本比例最高的类别\n",
    "            return decisionnode(d=d, thre=thre, min_sample_number=min_sample_number, lb=left_branch, rb=right_branch, max_label=max_label)\n",
    "        else:\n",
    "            max_label = maxlabel(y)\n",
    "            return decisionnode(results=y[0], min_sample_number=min_sample_number, max_label=max_label)\n",
    "    else:\n",
    "        max_label = maxlabel(y)\n",
    "        return decisionnode(results=y.item(), min_sample_number=min_sample_number, max_label=max_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.利用决策树对样本进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(observation, tree): # 利用决策树对样本进行分类\n",
    "    if tree.results != None:\n",
    "        return tree.results\n",
    "    else:\n",
    "        v = observation[tree.d]\n",
    "        branch = None\n",
    "        if v > tree.thre: \n",
    "            branch = tree.rb # 对应属性值大于thre的那些样本所在的结点\n",
    "        else:\n",
    "            branch = tree.lb # 对应属性值小于等于thre的那些样本所在的结点\n",
    "        return classify(observation, branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.调用决策树进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARTTree:0.96\n",
      "C3Tree:0.96\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    iris = load_iris()\n",
    "    X = iris.data # 获取iris数据集data属性的值，二维，行数等于样本数，列数等于特征数\n",
    "    y = iris.target # 获取iris数据集target属性的值\n",
    "    np.random.seed(0)\n",
    "    permutation = np.random.permutation(X.shape[0]) # 使用permutation随机打乱\n",
    "    shuffled_dataset = X[permutation, :]\n",
    "    shuffled_labels = y[permutation]\n",
    "\n",
    "    train_data = shuffled_dataset[:100, :] # 训练数据，所有列的前100行数据\n",
    "    train_label = shuffled_labels[:100] # 训练目标值，前100行\n",
    "\n",
    "    test_data = shuffled_dataset[100:150, :] # 测试数据\n",
    "    test_label = shuffled_labels[100:150] # 测试目标值\n",
    " \n",
    "    tree1 = buildtree(train_data, train_label, method='Gini') # 使用上方定义的buildtree()函数构建决策树1\n",
    "    tree2 = buildtree(train_data, train_label, method='GainEnt') # 使用上方定义的buildtree()函数构建决策树2\n",
    "\n",
    "    true_count = 0\n",
    "    for i in range(len(test_label)):\n",
    "        predict = classify(test_data[i], tree1) # 利用tree1对test_data进行分类\n",
    "        if predict == test_label[i]:\n",
    "            true_count += 1\n",
    "    acc=true_count/len(test_label) # 计算准确率\n",
    "    print(\"CARTTree:{}\".format(acc))\n",
    "    \n",
    "    true_count = 0\n",
    "    for i in range(len(test_label)):\n",
    "        predict = classify(test_data[i], tree2) # 利用tree2对test_data进行分类\n",
    "        if predict == test_label[i]:\n",
    "            true_count += 1\n",
    "    acc=true_count/len(test_label)\n",
    "    print(\"C3Tree:{}\".format(acc)) # 计算准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程序运行结束后，可在屏幕上输出 CART 决策树（使用基尼指数）和 C3 决策树（使用信息增益）在测试集上的分类准确率：  \n",
    "CARTTree:0.96  \n",
    "C3Tree:0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 扩展研究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def node_plot(object, node_name, master): # 绘制当前结点\n",
    "    if object.lb:   # 左支非空\n",
    "        # 当前结点信息\n",
    "        d = object.d\n",
    "        thre = object.thre\n",
    "        max_label = object.max_label\n",
    "        # 构建当前结点\n",
    "        master.node(node_name, label='d: %s\\nthre: %s\\nmax_label: %s' %(str(d), str(thre), str(max_label)) )\n",
    "        # 绘制子节点\n",
    "        node_plot(object.lb, node_name+'.lb', master)\n",
    "        # 连接当前结点和子结点\n",
    "        master.edge(node_name, node_name+'.lb')\n",
    "\n",
    "    if object.rb:   # 右支非空\n",
    "        # 当前结点信息\n",
    "        d = object.d\n",
    "        thre = object.thre\n",
    "        max_label = object.max_label\n",
    "        # 构建当前结点\n",
    "        master.node(node_name, label='d: %s\\nthre: %s\\nmax_label: %s' %(str(d), str(thre), str(max_label)) )\n",
    "        # 绘制子节点\n",
    "        node_plot(object.rb, node_name+'.rb', master)\n",
    "        # 连接当前结点和子结点\n",
    "        master.edge(node_name, node_name+'.rb')\n",
    "    \n",
    "    if not bool(object.lb or object.rb):    # 左右双空表示当前节点为叶节点\n",
    "        # 当前结点信息\n",
    "        results = object.results\n",
    "        # 构建当前结点\n",
    "        master.node(node_name, label='result: '+str(results))\n",
    "\n",
    "def graph(object, name):\n",
    "    viz = Digraph(name, filename='%s' %name)    # 建立画布\n",
    "    node_plot(object, name, master=viz)     # 从根节点开始画图\n",
    "    viz.view()  # 显示画布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph(tree1, 'tree1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph(tree2, 'tree2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "封装训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尽管sklearn有拆分训练集的函数，但是在这个以自己实现为主要目的的作业里，我们还是自己实现了\n",
    "def split_data(X, y, random_state, test_size):\n",
    "    np.random.seed(random_state)\n",
    "    permutation = np.random.permutation(X.shape[0]) # 使用permutation随机打乱\n",
    "    shuffled_dataset = X[permutation, :]\n",
    "    shuffled_labels = y[permutation]\n",
    "\n",
    "    train_amount = len(X) - int(len(X) * test_size)\n",
    "\n",
    "    train_data = shuffled_dataset[:train_amount, :] # 训练数据\n",
    "    train_label = shuffled_labels[:train_amount] # 训练目标值\n",
    "\n",
    "    test_data = shuffled_dataset[train_amount:, :] # 测试数据\n",
    "    test_label = shuffled_labels[train_amount:] # 测试目标值\n",
    "\n",
    "    return train_data, train_label, test_data, test_label\n",
    "\n",
    "def predict_and_evaluate(method, tree, test_data, test_label):\n",
    "    test_prediction = test_label.copy()\n",
    "    true_count = 0\n",
    "    for i in range(len(test_label)):\n",
    "        test_prediction[i] = classify(test_data[i], tree)   # 预测\n",
    "        if test_prediction[i] == test_label[i]:     # 评估判断\n",
    "            true_count += 1\n",
    "\n",
    "    acc=true_count/len(test_label) # 计算准确率\n",
    "    if method == 'Gini':\n",
    "        print(\"CARTTree:{}\".format(acc))\n",
    "    elif method == 'GainEnt':\n",
    "        print(\"C3Tree:{}\".format(acc))\n",
    "\n",
    "    return test_prediction, acc     # 返回预测结果和准确度\n",
    "    \n",
    "def fit(X, y, method, random_state=0, test_size=0.3):\n",
    "    # 载入数据\n",
    "    # 使用自己封装的划分\n",
    "    train_data, train_label, test_data, test_label = split_data(X, y, test_size=test_size, random_state=random_state)\n",
    "    # 使用sklearn的划分\n",
    "    # train_data, train_label, test_data, test_label = train_test_split(X, y, test_size=test_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "    print('train: %d\\ntest: %d' %(len(train_data), len(test_data)))\n",
    "\n",
    "    # 建立决策树\n",
    "    tree = buildtree(train_data, train_label, method=method) # 使用上方定义的buildtree()函数构建决策树\n",
    "\n",
    "    # 预测和评估\n",
    "    prediction, accuracy = predict_and_evaluate(method=method, tree=tree, test_data=test_data, test_label=test_label)\n",
    "\n",
    "    return tree, prediction, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 105\n",
      "test: 45\n",
      "CARTTree:0.9555555555555556\n",
      "train: 105\n",
      "test: 45\n",
      "C3Tree:0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    iris = load_iris()\n",
    "    CartTree, prediction, accuracy = fit(X = iris.data, y = iris.target, method = 'Gini', random_state=0, test_size=0.3)\n",
    "    graph(CartTree, 'CartTree')\n",
    "\n",
    "    C3Tree, prediction, accuracy = fit(X = iris.data, y = iris.target, method = 'GainEnt', random_state=0, test_size=0.3)\n",
    "    graph(C3Tree, 'C3Tree')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80f22b69b9f8d68ace34ab34260f84f100690723be29e4bfe0f6c780c6b4105c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
